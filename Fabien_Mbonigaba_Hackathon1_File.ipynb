{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FabienMiguel/NLP-Fellowship/blob/main/Fabien_Mbonigaba_Hackathon1_File.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi pyngrok uvicorn nest-asyncio"
      ],
      "metadata": {
        "id": "xOdQu9ICq3qE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U easynmt"
      ],
      "metadata": {
        "id": "CfHeD3snrZ-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbmBYNEFB7uY"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "from fastapi import FastAPI, Response\n",
        "from pyngrok import ngrok\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "from starlette.responses import HTMLResponse\n",
        "import json\n",
        "from easynmt import EasyNMT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set authentication for ngrok\n",
        "!ngrok authtoken 2HJQ5KFUMPejTBPPFOQGP2WRU74_o2vYuu2ZQcGb3zYD6ziq"
      ],
      "metadata": {
        "id": "P1hMhWytr6ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6y2Tr-VGWTzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Web scrapping JobinRwanda.com"
      ],
      "metadata": {
        "id": "gN8CLWoJwnB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SOUP\n",
        "link = 'https://www.jobinrwanda.com/jobs/featured'\n",
        "soup = BeautifulSoup(requests.get(link).content, 'html.parser')"
      ],
      "metadata": {
        "id": "FPq2kkfZCYLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LINKS OF ALL FEATURED CONTENT ON WEB\n",
        "# job title\n",
        "job_titles = {}\n",
        "\n",
        "divs = soup.find_all('div', class_ = 'card-body p-2')\n",
        "f_links = [] # this is featured links da means it contain all links from(jobs,tenders, and consultancy)\n",
        "\n",
        "for index,div in enumerate(divs):\n",
        "  anchor = div.find('a')\n",
        "  found_link = 'https://www.jobinrwanda.com'+anchor['href']\n",
        "  job_titles[index] = anchor.find('h5', class_ = 'card-title').get_text()\n",
        "  f_links.append(found_link)\n",
        "job_titles = list(job_titles.values())"
      ],
      "metadata": {
        "id": "JN5sXNmQxMGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_titles"
      ],
      "metadata": {
        "id": "rThpjx3oQDQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EACH LINK SOUP\n",
        "l_soups = {}\n",
        "for index,link in enumerate(f_links):\n",
        "  SOUP = BeautifulSoup(requests.get(link).content, 'html.parser')\n",
        "  l_soups[index] = SOUP"
      ],
      "metadata": {
        "id": "BCRSt5nxCOwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DIVS FOR EACH FEATURE CONTENT\n",
        "content_divs = {}\n",
        "job_info = {}\n",
        "for index,soup1 in enumerate(list(l_soups.values())):\n",
        "  content_divs[index] = soup1.find('div', class_ = 'clearfix text-formatted field field--name-field-job-full-description field--type-text-long field--label-hidden field__item')\n",
        "  ul = soup1.find('ul', class_ = 'list-group list-group-flush')\n",
        "  lists = {}\n",
        "  for li in ul.children:\n",
        "    try:\n",
        "      info = re.sub('\\s{2,}|\\n',' ',li.text) # both key and value together as str\n",
        "      # separate key & value to get key:value dictionary\n",
        "      if not 'apply' in info.lower():\n",
        "        if 'viewed' in info:\n",
        "          times = re.search('\\d+', info).group()\n",
        "          lists['views'] = times\n",
        "        else:\n",
        "          k,value = re.split(':', info)[:2]\n",
        "          lists[k.lstrip()] = value\n",
        "    except AttributeError:\n",
        "      pass\n",
        "  job_info[index] = lists\n"
      ],
      "metadata": {
        "id": "lqlsLuwW0Y0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# COMBINATION OF FULL CONTENT OF EACH FEATURE(jobs,tenders, and consultancy)\n",
        "full_content = {}\n",
        "for index,div in enumerate(list(content_divs.values())):\n",
        "  one_div_content = []\n",
        "  for para in div.find_all('p', class_ = 'text-align-justify'):\n",
        "    one_div_content.append(para.get_text())\n",
        "  full_content[index] = re.sub('\\n|\\\\xa0','','\\n'.join(one_div_content))  # use regex to clean unwanted stuff in my text content"
      ],
      "metadata": {
        "id": "01HGW59h1pFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_content "
      ],
      "metadata": {
        "id": "9ilX4ilnITBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#[['location: Kigali','views','job des','feature 1 content'],['feature 2'],[],[]]\n",
        "final = []\n",
        "for index in list(content_divs.keys()):\n",
        "  index_info = list(job_info[index].values())\n",
        "  index_text = [full_content[index]]\n",
        "  final.append(index_info + index_text)\n",
        "final\n"
      ],
      "metadata": {
        "id": "ieo8mdHS13xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = list(job_info[0].keys()) + ['Description']\n",
        "len(columns)"
      ],
      "metadata": {
        "id": "-R346CChJLIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = pd.DataFrame(final, columns = columns)"
      ],
      "metadata": {
        "id": "wI7aVQ2lLcRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe['job title'] = job_titles"
      ],
      "metadata": {
        "id": "3vFXvZDpQX8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe['job title'] = dataframe['job title'].str.replace('\\n','',regex=True).astype('str')"
      ],
      "metadata": {
        "id": "trUnPleLHs1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "only_IT_jobs = dataframe.copy()\n",
        "only_IT_jobs['is IT job'] = False\n",
        "\n",
        "for index in range(len(only_IT_jobs)):\n",
        "  if re.findall('Computer|IT|Software', only_IT_jobs.iloc[index]['Sector']):\n",
        "    only_IT_jobs['is IT job'][index] = True"
      ],
      "metadata": {
        "id": "kASSWLtSULIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "only_IT_jobs = only_IT_jobs[only_IT_jobs['is IT job'] == True]   # filter for the IT job"
      ],
      "metadata": {
        "id": "P8s8XQg6XoqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "only_IT_jobs"
      ],
      "metadata": {
        "id": "YeGHOAAQZLFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Webscrapping Umucyo.com"
      ],
      "metadata": {
        "id": "gU478F3vbcVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#use view source code tool to fetch HTML page Soup\n",
        "url = 'https://www.umucyo.gov.rw/eb/bav/selectListAdvertisingListForGU.do'\n",
        "data = \"\"\"\"\"\"\n",
        "with open('/content/drive/MyDrive/NLP Fellowship/weekend/Umucyo.txt', 'r') as f:\n",
        "  text = f.readlines()\n",
        "  for line in text:\n",
        "    data += line\n",
        "umucyo_soup = BeautifulSoup(data, 'html.parser')\n",
        "table = umucyo_soup.find('table', class_ = 'article_table mb10')"
      ],
      "metadata": {
        "id": "t5Ivmgdjbbis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "head_row = table.find('thead').find('tr')\n",
        "titles = []\n",
        "for th in head_row.find_all('th'):\n",
        "  titles.append(re.sub('\\r|\\n|\\t','',th.text)) #using regx to clean my table titles\n",
        "titles = titles[1:]"
      ],
      "metadata": {
        "id": "2TOfd6QrcRmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titles"
      ],
      "metadata": {
        "id": "bC2OIqXDdRur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# table body\n",
        "body_rows = table.find('tbody').find_all('tr') \n",
        "full_data = []\n",
        "for row in body_rows:\n",
        "  ls = []\n",
        "  for detail in row.find_all('td'):\n",
        "    ls.append(re.sub('\\n|\\r|\\t|\\s', '',detail.text))  #using regx to clean unwanted spaces and other stuff in my list\n",
        "  full_data.append(ls[1:])\n"
      ],
      "metadata": {
        "id": "S5Bjm8n1d3c2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# full_data"
      ],
      "metadata": {
        "id": "KXmbptISfKW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "umucyo_df = pd.DataFrame(full_data, columns = titles)"
      ],
      "metadata": {
        "id": "_Nb7INlcft7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "umucyo_df"
      ],
      "metadata": {
        "id": "pD93YRn8f6s5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataframe translation in 50+ Languanges using EasyNMT Library"
      ],
      "metadata": {
        "id": "TNcQzor1p8Gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = EasyNMT('opus-mt')\n",
        "app = FastAPI(title = 'Tough time never last but tough people do!')"
      ],
      "metadata": {
        "id": "hb5kbWrROQpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show all IT jobs\n",
        "\n",
        "@app.get('/itjobs')\n",
        "def show(orient:str='index'):\n",
        "    return Response(only_IT_jobs.to_json(orient = orient), media_type = 'application/json')"
      ],
      "metadata": {
        "id": "Cqxpr6ExIeoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show all information from jobinrwanda\n",
        "@app.get('/jobinrwanda_all')\n",
        "def showall(orient:str='index'):\n",
        "    return Response(dataframe.to_json(orient = orient), media_type = 'application/json')"
      ],
      "metadata": {
        "id": "1lDRVFEdFhd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show all information retrieved from umucyo\n",
        "@app.get('/umucyo_all')\n",
        "def show_umucyo(orient:str='index'):\n",
        "    return Response(umucyo_df.to_json(orient = orient), media_type = 'application/json')"
      ],
      "metadata": {
        "id": "EJMkMhJkFoZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basically Translation!!\n",
        "prev_lang = 'en'\n",
        "@app.get('/translate')\n",
        "def dr(lang:str=''):\n",
        "  global prev_lang\n",
        "  success = True\n",
        "  if lang:\n",
        "    try:\n",
        "      d = []\n",
        "      f = []\n",
        "      for index in range(len(only_IT_jobs)):\n",
        "        text1 = only_IT_jobs.iloc[index]['Description']\n",
        "        text2 = only_IT_jobs.iloc[index]['job title']\n",
        "        d.append(model.translate(text1, source_lang = prev_lang, target_lang = lang))\n",
        "        f.append(model.translate(text2, source_lang = prev_lang, target_lang = lang))\n",
        "        if index != len(only_IT_jobs) - 1:\n",
        "          print(f\"{index} / {len(only_IT_jobs)}\")\n",
        "      only_IT_jobs['job title'] = f\n",
        "      only_IT_jobs['Description'] = d\n",
        "      success = True\n",
        "      prev_lang = lang\n",
        "    except:\n",
        "      error_message = f\"\"\"<html>\n",
        "                            <h2>\n",
        "                              Oops! Something went wrong. <br> please, Try to choose other language!!!.\n",
        "                            </h2>\n",
        "                          </html>\"\"\"\n",
        "      success = False\n",
        "      return HTMLResponse(error_message)\n",
        "  if success:\n",
        "    return Response(only_IT_jobs.to_json(orient = 'index'), media_type = 'application/json')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xRG9b9neQexa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tunnel = ngrok.connect(8000)\n",
        "print(\"PUBLIC URL: \", tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port = 8000)"
      ],
      "metadata": {
        "id": "xp6x2pcKKv80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cs = only_IT_jobs.to_csv('miguel.csv')"
      ],
      "metadata": {
        "id": "k_o0_M7R_tHP"
      },
      "execution_count": 183,
      "outputs": []
    }
  ]
}